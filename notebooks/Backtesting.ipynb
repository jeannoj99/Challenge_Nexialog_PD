{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(CVXPY) Apr 02 07:32:58 PM: Encountered unexpected exception importing solver GLOP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.8.3296). Expected < 9.8.0. Please open a feature request on cvxpy to enable support for this version.')\n",
      "(CVXPY) Apr 02 07:32:58 PM: Encountered unexpected exception importing solver PDLP:\n",
      "RuntimeError('Unrecognized new version of ortools (9.8.3296). Expected < 9.8.0. Please open a feature request on cvxpy to enable support for this version.')\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optbinning as opt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler,KBinsDiscretizer, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import mannwhitneyu ,chi2_contingency, anderson, f_oneway\n",
    "import statsmodels.api as sm \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"../data/application_train_vf.csv\",parse_dates=[\"date_mensuelle\"], index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_bureau_data=pd.read_csv(\"../data/cb_findings.csv\", index_col=0)\n",
    "data=data.merge(credit_bureau_data, left_on=\"SK_ID_CURR\", right_on=\"CB_SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"date_annee\"]=data[\"date_mensuelle\"].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reference = data[data[\"date_annee\"] < 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_backtest = data[data[\"date_annee\"] == 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mandatory_columns=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_integrity_assessment(df):\n",
    "    if True:\n",
    "        return True\n",
    "    else :\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_integrity_assessment(data_backtest) == False :\n",
    "    StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of mandatory features et application of discretisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Application of score card \n",
    "data_reference[\"Segment\"] = np.random.randint(0,7,data_reference.shape[0])\n",
    "data_backtest[\"Segment\"] = np.random.randint(0,7,data_backtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "toto=data_backtest[\"Segment\"].value_counts(normalize=True).reset_index()\n",
    "tata = data_reference[\"Segment\"].value_counts(normalize=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "titi=tata.merge(toto, how=\"outer\", on=\"Segment\", suffixes=(\"_reference\",\"_backtest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>proportion_reference</th>\n",
       "      <th>proportion_backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.142573</td>\n",
       "      <td>0.147169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.143182</td>\n",
       "      <td>0.144797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.142110</td>\n",
       "      <td>0.141982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.143063</td>\n",
       "      <td>0.144198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.143249</td>\n",
       "      <td>0.141330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.143630</td>\n",
       "      <td>0.140444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.142192</td>\n",
       "      <td>0.140079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Segment  proportion_reference  proportion_backtest\n",
       "0        0              0.142573             0.147169\n",
       "1        1              0.143182             0.144797\n",
       "2        2              0.142110             0.141982\n",
       "3        3              0.143063             0.144198\n",
       "4        4              0.143249             0.141330\n",
       "5        5              0.143630             0.140444\n",
       "6        6              0.142192             0.140079"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_contribution_to_is(x):\n",
    "    return (x[\"proportion_reference\"] - x[\"proportion_backtest\"])*np.log(x[\"proportion_reference\"] / x[\"proportion_backtest\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "titi[\"contribution\"]=titi.apply(calculate_contribution_to_is, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>proportion_reference</th>\n",
       "      <th>proportion_backtest</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Segment  proportion_reference  proportion_backtest  contribution\n",
       "0     21.0                   1.0                  1.0      0.000302"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(titi.apply(np.sum, axis=0)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "titi = pd.concat([titi,pd.DataFrame(titi.apply(np.sum, axis=0)).T], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>proportion_reference</th>\n",
       "      <th>proportion_backtest</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142573</td>\n",
       "      <td>0.147169</td>\n",
       "      <td>1.458148e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.143182</td>\n",
       "      <td>0.144797</td>\n",
       "      <td>1.811696e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.142110</td>\n",
       "      <td>0.141982</td>\n",
       "      <td>1.155075e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.143063</td>\n",
       "      <td>0.144198</td>\n",
       "      <td>8.971013e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.143249</td>\n",
       "      <td>0.141330</td>\n",
       "      <td>2.587829e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.143630</td>\n",
       "      <td>0.140444</td>\n",
       "      <td>7.147209e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.142192</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>3.163771e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.020063e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Segment  proportion_reference  proportion_backtest  contribution\n",
       "0      0.0              0.142573             0.147169  1.458148e-04\n",
       "1      1.0              0.143182             0.144797  1.811696e-05\n",
       "2      2.0              0.142110             0.141982  1.155075e-07\n",
       "3      3.0              0.143063             0.144198  8.971013e-06\n",
       "4      4.0              0.143249             0.141330  2.587829e-05\n",
       "5      5.0              0.143630             0.140444  7.147209e-05\n",
       "6      6.0              0.142192             0.140079  3.163771e-05\n",
       "7     21.0              1.000000             1.000000  3.020063e-04"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "titi[\"Segment\"][-1:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Segment</th>\n",
       "      <th>proportion_reference</th>\n",
       "      <th>proportion_backtest</th>\n",
       "      <th>contribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142573</td>\n",
       "      <td>0.147169</td>\n",
       "      <td>1.458148e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.143182</td>\n",
       "      <td>0.144797</td>\n",
       "      <td>1.811696e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.142110</td>\n",
       "      <td>0.141982</td>\n",
       "      <td>1.155075e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.143063</td>\n",
       "      <td>0.144198</td>\n",
       "      <td>8.971013e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.143249</td>\n",
       "      <td>0.141330</td>\n",
       "      <td>2.587829e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.143630</td>\n",
       "      <td>0.140444</td>\n",
       "      <td>7.147209e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.142192</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>3.163771e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.020063e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Segment  proportion_reference  proportion_backtest  contribution\n",
       "0      0.0              0.142573             0.147169  1.458148e-04\n",
       "1      1.0              0.143182             0.144797  1.811696e-05\n",
       "2      2.0              0.142110             0.141982  1.155075e-07\n",
       "3      3.0              0.143063             0.144198  8.971013e-06\n",
       "4      4.0              0.143249             0.141330  2.587829e-05\n",
       "5      5.0              0.143630             0.140444  7.147209e-05\n",
       "6      6.0              0.142192             0.140079  3.163771e-05\n",
       "7      NaN              1.000000             1.000000  3.020063e-04"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reference[\"Note\"]=np.random.randint(0,1001,data_reference.shape[0])\n",
    "data_backtest[\"Note\"]=np.random.randint(0,1001,data_backtest.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### System Stability Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSI \n",
    "def system_stability_index(reference,backtest):\n",
    "    dist_ref = reference[\"Segment\"].value_counts(normalize=True).reset_index()\n",
    "    dist_back = backtest[\"Segment\"].value_counts(normalize=True).reset_index()\n",
    "    dist_all = dist_ref.merge(dist_back, how=\"outer\", on=\"Segment\", suffixes=(\"_reference\",\"_backtest\"))\n",
    "    dist_all[\"contribution\"]=dist_all.apply(calculate_contribution_to_is, axis=1)\n",
    "    dist_all = pd.concat([dist_all,pd.DataFrame(dist_all.apply(np.sum, axis=0)).T], axis=0, ignore_index=True)\n",
    "    dist_all[\"Segment\"][-1:] = np.nan\n",
    "    return dist_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.0033123477128031986, pvalue=0.8539633484066944, statistic_location=511, statistic_sign=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ks_2samp(data1=data_reference[\"Note\"], data2=data_backtest[\"Note\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KS test\n",
    "def kolmogorov_smirnov_test(reference, backtest,colname):\n",
    "    results = ks_2samp(data1=reference[colname], data2=backtest[colname])\n",
    "    if results[1] < 0.05:\n",
    "        print(f\"Null hypothesis is rejected : The distributions of {colname} are not the same\")\n",
    "    else :\n",
    "        print(f\"Null hypothesis is not rejected : The distributions of {colname} are the same\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeann\\Desktop\\M2\\Credit Risk Modelling\\PD_Model_Nexialog\\Challenge_Nexialog_PD\\.venv_pd\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "c:\\Users\\jeann\\Desktop\\M2\\Credit Risk Modelling\\PD_Model_Nexialog\\Challenge_Nexialog_PD\\.venv_pd\\Lib\\site-packages\\deap\\creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen\tnevals\n",
      "0  \t50    \n",
      "1  \t39    \n",
      "2  \t38    \n",
      "3  \t29    \n",
      "4  \t44    \n",
      "5  \t41    \n",
      "6  \t44    \n",
      "7  \t39    \n",
      "8  \t31    \n",
      "9  \t37    \n",
      "10 \t41    \n",
      "11 \t42    \n",
      "12 \t44    \n",
      "13 \t30    \n",
      "14 \t42    \n",
      "15 \t40    \n",
      "16 \t39    \n",
      "17 \t40    \n",
      "18 \t35    \n",
      "19 \t35    \n",
      "20 \t42    \n",
      "21 \t40    \n",
      "22 \t40    \n",
      "23 \t32    \n",
      "24 \t43    \n",
      "25 \t35    \n",
      "26 \t41    \n",
      "27 \t33    \n",
      "28 \t38    \n",
      "29 \t37    \n",
      "30 \t35    \n",
      "31 \t46    \n",
      "32 \t38    \n",
      "33 \t39    \n",
      "34 \t40    \n",
      "35 \t38    \n",
      "36 \t40    \n",
      "37 \t46    \n",
      "38 \t37    \n",
      "39 \t40    \n",
      "40 \t42    \n",
      "41 \t39    \n",
      "42 \t36    \n",
      "43 \t33    \n",
      "44 \t39    \n",
      "45 \t38    \n",
      "46 \t47    \n",
      "47 \t32    \n",
      "48 \t35    \n",
      "49 \t39    \n",
      "50 \t36    \n",
      "51 \t45    \n",
      "52 \t36    \n",
      "53 \t43    \n",
      "54 \t38    \n",
      "55 \t31    \n",
      "56 \t32    \n",
      "57 \t34    \n",
      "58 \t37    \n",
      "59 \t35    \n",
      "60 \t33    \n",
      "61 \t38    \n",
      "62 \t39    \n",
      "63 \t36    \n",
      "64 \t31    \n",
      "65 \t38    \n",
      "66 \t35    \n",
      "67 \t40    \n",
      "68 \t41    \n",
      "69 \t27    \n",
      "70 \t39    \n",
      "71 \t30    \n",
      "72 \t33    \n",
      "73 \t43    \n",
      "74 \t36    \n",
      "75 \t36    \n",
      "76 \t37    \n",
      "77 \t34    \n",
      "78 \t40    \n",
      "79 \t39    \n",
      "80 \t33    \n",
      "81 \t40    \n",
      "82 \t36    \n",
      "83 \t33    \n",
      "84 \t32    \n",
      "85 \t38    \n",
      "86 \t39    \n",
      "87 \t37    \n",
      "88 \t42    \n",
      "89 \t38    \n",
      "90 \t38    \n",
      "91 \t33    \n",
      "92 \t41    \n",
      "93 \t33    \n",
      "94 \t42    \n",
      "95 \t37    \n",
      "96 \t34    \n",
      "97 \t40    \n",
      "98 \t35    \n",
      "99 \t37    \n",
      "100\t39    \n",
      "Meilleurs points de coupe pour la segmentation : [-697.8816460599154, 496.907480829212, 609.2018937508757, 789.1035928750846, 13774.633822079912, 75395.92680738079]\n",
      "Variance intra-segment et -Variance inter-segment : (28427.41367536614, -63764.964104524)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "# Simulons une variable numérique comme exemple\n",
    "np.random.seed(42)  # Pour la reproductibilité\n",
    "data = np.random.randint(0, 1001, size=1000)\n",
    "\n",
    "# Nombre de segments\n",
    "n_segments = 7\n",
    "\n",
    "# Fonction pour calculer la variance intra-segment et inter-segment\n",
    "def evalSegments(individual):\n",
    "    # Tri des points de coupe\n",
    "    cuts = sorted(individual)\n",
    "    # Ajout des limites\n",
    "    segments = [-np.inf] + cuts + [np.inf]\n",
    "    # Calcul des moyennes et variances intra-segment\n",
    "    var_intra = 0\n",
    "    means = []\n",
    "    for i in range(len(segments) - 1):\n",
    "        segment_data = data[(data > segments[i]) & (data <= segments[i+1])]\n",
    "        if len(segment_data) > 0:\n",
    "            var_intra += np.var(segment_data)\n",
    "            means.append(np.mean(segment_data))\n",
    "    # Calcul de la variance inter-segments\n",
    "    mean_global = np.mean(data)\n",
    "    var_inter = np.mean([(mean - mean_global)**2 for mean in means])\n",
    "    # L'objectif est de minimiser la variance intra-segment et maximiser la variance inter-segment\n",
    "    return (var_intra, -var_inter)\n",
    "\n",
    "# Configuration de l'algorithme génétique\n",
    "creator.create(\"FitnessMulti\", base.Fitness, weights=(-1.0, 1.0))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMulti)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_float\", np.random.uniform, np.min(data), np.max(data))\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, n=n_segments-1)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evalSegments)\n",
    "toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=5, indpb=0.2)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "# Paramètres de l'algorithme\n",
    "population_size = 50\n",
    "number_of_generations = 100\n",
    "crossover_probability = 0.7\n",
    "mutation_probability = 0.2\n",
    "\n",
    "# Initialisation de la population\n",
    "pop = toolbox.population(n=population_size)\n",
    "\n",
    "# Lancement de l'algorithme génétique\n",
    "final_population = algorithms.eaSimple(pop, toolbox, cxpb=crossover_probability, mutpb=mutation_probability, ngen=number_of_generations, verbose=True)\n",
    "\n",
    "# Meilleure solution\n",
    "best_ind = tools.selBest(pop, 1)[0]\n",
    "print(\"Meilleurs points de coupe pour la segmentation :\", sorted(best_ind))\n",
    "print(\"Variance intra-segment et -Variance inter-segment :\", evalSegments(best_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84014.80395900001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "slice indices must be integers or None or have an __index__ method\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeann\\Desktop\\M2\\Credit Risk Modelling\\PD_Model_Nexialog\\Challenge_Nexialog_PD\\.venv_pd\\Lib\\site-packages\\pygad\\pygad.py\", line 1708, in cal_pop_fitness\n",
      "    fitness = self.fitness_func(self, sol, sol_idx)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jeann\\AppData\\Local\\Temp\\ipykernel_25612\\2022504055.py\", line 19, in fitness_func\n",
      "    segment_means.append(np.mean(sorted_data[start_idx:end_idx]))\n",
      "                                 ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: slice indices must be integers or None or have an __index__ method\n",
      "slice indices must be integers or None or have an __index__ method\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeann\\Desktop\\M2\\Credit Risk Modelling\\PD_Model_Nexialog\\Challenge_Nexialog_PD\\.venv_pd\\Lib\\site-packages\\pygad\\pygad.py\", line 1914, in run\n",
      "    self.last_generation_fitness = self.cal_pop_fitness()\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeann\\Desktop\\M2\\Credit Risk Modelling\\PD_Model_Nexialog\\Challenge_Nexialog_PD\\.venv_pd\\Lib\\site-packages\\pygad\\pygad.py\", line 1871, in cal_pop_fitness\n",
      "    raise ex\n",
      "  File \"c:\\Users\\jeann\\Desktop\\M2\\Credit Risk Modelling\\PD_Model_Nexialog\\Challenge_Nexialog_PD\\.venv_pd\\Lib\\site-packages\\pygad\\pygad.py\", line 1708, in cal_pop_fitness\n",
      "    fitness = self.fitness_func(self, sol, sol_idx)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jeann\\AppData\\Local\\Temp\\ipykernel_25612\\2022504055.py\", line 19, in fitness_func\n",
      "    segment_means.append(np.mean(sorted_data[start_idx:end_idx]))\n",
      "                                 ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: slice indices must be integers or None or have an __index__ method\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "slice indices must be integers or None or have an __index__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 46\u001b[0m\n\u001b[0;32m     34\u001b[0m ga_instance \u001b[38;5;241m=\u001b[39m pygad\u001b[38;5;241m.\u001b[39mGA(num_generations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     35\u001b[0m                        num_parents_mating\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     36\u001b[0m                        sol_per_pop\u001b[38;5;241m=\u001b[39mpopulation_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m                        mutation_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     43\u001b[0m                        mutation_percent_genes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Exécution de l'algorithme génétique\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[43mga_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jeann\\Desktop\\M2\\Credit Risk Modelling\\PD_Model_Nexialog\\Challenge_Nexialog_PD\\.venv_pd\\Lib\\site-packages\\pygad\\pygad.py:2095\u001b[0m, in \u001b[0;36mGA.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mexception(ex)\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# sys.exit(-1)\u001b[39;00m\n\u001b[1;32m-> 2095\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[1;32mc:\\Users\\jeann\\Desktop\\M2\\Credit Risk Modelling\\PD_Model_Nexialog\\Challenge_Nexialog_PD\\.venv_pd\\Lib\\site-packages\\pygad\\pygad.py:1914\u001b[0m, in \u001b[0;36mGA.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1911\u001b[0m     generation_last_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_generations\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;66;03m# Measuring the fitness of each chromosome in the population. Save the fitness in the last_generation_fitness attribute.\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_generation_fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcal_pop_fitness\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1916\u001b[0m best_solution, best_solution_fitness, best_match_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_solution(pop_fitness\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_generation_fitness)\n\u001b[0;32m   1918\u001b[0m \u001b[38;5;66;03m# Appending the best solution in the initial population to the best_solutions list.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jeann\\Desktop\\M2\\Credit Risk Modelling\\PD_Model_Nexialog\\Challenge_Nexialog_PD\\.venv_pd\\Lib\\site-packages\\pygad\\pygad.py:1871\u001b[0m, in \u001b[0;36mGA.cal_pop_fitness\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1869\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mexception(ex)\n\u001b[0;32m   1870\u001b[0m     \u001b[38;5;66;03m# sys.exit(-1)\u001b[39;00m\n\u001b[1;32m-> 1871\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[0;32m   1872\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pop_fitness\n",
      "File \u001b[1;32mc:\\Users\\jeann\\Desktop\\M2\\Credit Risk Modelling\\PD_Model_Nexialog\\Challenge_Nexialog_PD\\.venv_pd\\Lib\\site-packages\\pygad\\pygad.py:1708\u001b[0m, in \u001b[0;36mGA.cal_pop_fitness\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1705\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1706\u001b[0m     \u001b[38;5;66;03m# Check if batch processing is used. If not, then calculate this missing fitness value.\u001b[39;00m\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness_batch_size \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m-> 1708\u001b[0m         fitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfitness_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msol_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1709\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(fitness) \u001b[38;5;129;01min\u001b[39;00m GA\u001b[38;5;241m.\u001b[39msupported_int_float_types:\n\u001b[0;32m   1710\u001b[0m             \u001b[38;5;66;03m# The fitness function returns a single numeric value.\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m             \u001b[38;5;66;03m# This is a single-objective optimization problem.\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m, in \u001b[0;36mfitness_func\u001b[1;34m(solution, solution_idx, ga_instance)\u001b[0m\n\u001b[0;32m     17\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m end_idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(solution):\n\u001b[1;32m---> 19\u001b[0m     segment_means\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(\u001b[43msorted_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_idx\u001b[49m\u001b[43m:\u001b[49m\u001b[43mend_idx\u001b[49m\u001b[43m]\u001b[49m))\n\u001b[0;32m     20\u001b[0m     start_idx \u001b[38;5;241m=\u001b[39m end_idx\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Calcul de la variance intra-segment\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: slice indices must be integers or None or have an __index__ method"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pygad\n",
    "\n",
    "# Définition de la variable numérique à segmenter\n",
    "np.random.seed(0)\n",
    "variable_numerique = np.random.randint(0, 1001, size=1000)\n",
    "\n",
    "# Définition de la fonction de coût pour minimiser la variance intra-segment\n",
    "def fitness_func(solution, solution_idx, ga_instance):\n",
    "    global variable_numerique\n",
    "    # Tri des données selon les segments\n",
    "    sorted_idx = np.argsort(solution)\n",
    "    sorted_data = variable_numerique[sorted_idx]\n",
    "    \n",
    "    # Calcul des moyennes des segments\n",
    "    segment_means = []\n",
    "    start_idx = 0\n",
    "    for end_idx in np.unique(solution):\n",
    "        segment_means.append(np.mean(sorted_data[start_idx:end_idx]))\n",
    "        start_idx = end_idx\n",
    "    \n",
    "    # Calcul de la variance intra-segment\n",
    "    intra_segment_variance = np.mean([(x - segment_means[i])**2 for i, x in enumerate(sorted_data)])\n",
    "    \n",
    "    \n",
    "    return intra_segment_variance\n",
    "\n",
    "# Définition des limites pour les gènes (les segments)\n",
    "num_genes = 1000\n",
    "gene_space = [{\"low\": 0, \"high\": 6}] * num_genes\n",
    "\n",
    "# Initialisation de la population\n",
    "population_size = 100\n",
    "ga_instance = pygad.GA(num_generations=50,\n",
    "                       num_parents_mating=50,\n",
    "                       sol_per_pop=population_size,\n",
    "                       num_genes=num_genes,\n",
    "                       gene_space=gene_space,\n",
    "                       fitness_func=fitness_func,\n",
    "                       parent_selection_type=\"tournament\",\n",
    "                       crossover_type=\"two_points\",\n",
    "                       mutation_type=\"random\",\n",
    "                       mutation_percent_genes=10)\n",
    "\n",
    "# Exécution de l'algorithme génétique\n",
    "ga_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Meilleure solution : \", solution)\n",
    "print(\"Valeur de fitness de la meilleure solution : \", solution_fitness)\n",
    "\n",
    "# Tri des données selon la solution trouvée\n",
    "sorted_idx = np.argsort(solution)\n",
    "sorted_data = variable_numerique[sorted_idx]\n",
    "\n",
    "# Affichage des segments\n",
    "start_idx = 0\n",
    "for end_idx in np.unique(solution):\n",
    "    print(\"Segment\", end_idx + 1, \":\", sorted_data[start_idx:end_idx+1])\n",
    "    start_idx = end_idx + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
