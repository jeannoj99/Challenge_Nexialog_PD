{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "class PdScorer:\n",
    "    def __init__(self, fitted_model):\n",
    "        self.model = fitted_model\n",
    "        self.grid_scores = self.create_grid_scores()\n",
    "\n",
    "    def create_grid_scores(self):\n",
    "        # Extraction des coefficients estimés du modèle\n",
    "        coefficients = self.model.params\n",
    "\n",
    "        # Normalisation des coefficients pour les rendre comparables\n",
    "        normalized_coefficients = (coefficients - coefficients.min()) / (coefficients.max() - coefficients.min())\n",
    "\n",
    "        # Création d'une grille de score sur mille basée sur les coefficients normalisés\n",
    "        grid_scores = np.round(normalized_coefficients * 1000).astype(int)\n",
    "\n",
    "        return grid_scores\n",
    "\n",
    "    def get_grid_scores(self):\n",
    "        return self.grid_scores\n",
    "\n",
    "    def transform(self, data, target_col):\n",
    "        # Ajoute une colonne constante pour intercept dans data\n",
    "        data = sm.add_constant(data)\n",
    "\n",
    "        # Extraction de la variable cible (target)\n",
    "        y = data[target_col]\n",
    "\n",
    "        # Suppression de la variable cible du DataFrame\n",
    "        data = data.drop(columns=[target_col])\n",
    "\n",
    "        # Calcul des scores normalisés sur mille en utilisant les coefficients normalisés\n",
    "        normalized_scores = np.dot(data, self.grid_scores[1:]) + self.grid_scores[0]\n",
    "\n",
    "        # Transformation des scores normalisés en scores sur 1000\n",
    "        scores_on_thousand = np.round((normalized_scores - normalized_scores.min()) / (normalized_scores.max() - normalized_scores.min()) * 1000).astype(int)\n",
    "\n",
    "        return scores_on_thousand\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation\n",
    "# Génération de données d'exemple (remplacez X et y par vos propres données)\n",
    "np.random.seed(42)\n",
    "data1 = pd.DataFrame({\n",
    "    'Category1': np.random.choice(['A', 'B', 'C'], size=100),\n",
    "    'Category2': np.random.choice(['X', 'Y', 'Z'], size=100),\n",
    "    'Variable1': np.random.rand(100),\n",
    "    'Variable2': np.random.rand(100),\n",
    "    'Target': np.random.choice([0, 1], size=100),\n",
    "})\n",
    "\n",
    "data2 = pd.DataFrame({\n",
    "    'Category1': np.random.choice(['A', 'B', 'C'], size=50),\n",
    "    'Category2': np.random.choice(['X', 'Y', 'Z'], size=50),\n",
    "    'Variable1': np.random.rand(50),\n",
    "    'Variable2': np.random.rand(50),\n",
    "    'Target': np.random.choice([0, 1], size=50),\n",
    "})\n",
    "\n",
    "# Spécification de la formule pour le modèle logistique\n",
    "formula = 'Target ~ Category1 + Category2 + Variable1 + Variable2'\n",
    "\n",
    "# Estimation du modèle de régression logistique avec statsmodels\n",
    "logit_model = sm.Logit.from_formula(formula, data1)\n",
    "fitted_model = logit_model.fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   No. Observations:                  100\n",
      "Model:                          Logit   Df Residuals:                       93\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Sat, 24 Feb 2024   Pseudo R-squ.:                 0.04872\n",
      "Time:                        09:41:52   Log-Likelihood:                -65.633\n",
      "converged:                       True   LL-Null:                       -68.994\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3472\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          0.9446      0.670      1.410      0.159      -0.369       2.258\n",
      "Category1[T.B]    -0.2421      0.505     -0.479      0.632      -1.232       0.748\n",
      "Category1[T.C]     0.4621      0.528      0.875      0.381      -0.573       1.497\n",
      "Category2[T.Y]    -0.1554      0.564     -0.276      0.783      -1.261       0.950\n",
      "Category2[T.Z]    -0.6957      0.496     -1.402      0.161      -1.668       0.277\n",
      "Variable1         -0.9944      0.793     -1.253      0.210      -2.549       0.561\n",
      "Variable2          0.1065      0.710      0.150      0.881      -1.285       1.498\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(fitted_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grille de score sur mille:\n",
      "Intercept         1000\n",
      "Category1[T.B]     388\n",
      "Category1[T.C]     751\n",
      "Category2[T.Y]     433\n",
      "Category2[T.Z]     154\n",
      "Variable1            0\n",
      "Variable2          568\n",
      "dtype: int32\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (100,5) and (6,) not aligned: 5 (dim 1) != 6 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid_scores)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Utilisation de la méthode transform pour obtenir les scores sur 1000 pour data1\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Assurez-vous que les noms de colonnes dans 'data1' correspondent à ceux utilisés dans le modèle\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m scores_data1 \u001b[38;5;241m=\u001b[39m \u001b[43mpd_scorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Affichage des 10 premiers scores pour data1\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mScores sur 1000 pour les 10 premières lignes de data1:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m, in \u001b[0;36mPdScorer.transform\u001b[1;34m(self, data, target_col)\u001b[0m\n\u001b[0;32m     33\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[target_col])\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Calcul des scores normalisés sur mille en utilisant les coefficients normalisés\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m normalized_scores \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_scores[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Transformation des scores normalisés en scores sur 1000\u001b[39;00m\n\u001b[0;32m     39\u001b[0m scores_on_thousand \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround((normalized_scores \u001b[38;5;241m-\u001b[39m normalized_scores\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m/\u001b[39m (normalized_scores\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m normalized_scores\u001b[38;5;241m.\u001b[39mmin()) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (100,5) and (6,) not aligned: 5 (dim 1) != 6 (dim 0)"
     ]
    }
   ],
   "source": [
    "# Instanciation de la classe PdScorer avec le modèle ajusté\n",
    "pd_scorer = PdScorer(fitted_model)\n",
    "\n",
    "# Utilisation de la méthode get_grid_scores pour obtenir la grille de score\n",
    "grid_scores = pd_scorer.get_grid_scores()\n",
    "print(\"Grille de score sur mille:\")\n",
    "print(grid_scores)\n",
    "\n",
    "# Utilisation de la méthode transform pour obtenir les scores sur 1000 pour data1\n",
    "# Assurez-vous que les noms de colonnes dans 'data1' correspondent à ceux utilisés dans le modèle\n",
    "scores_data1 = pd_scorer.transform(data1, 'Target')\n",
    "# Affichage des 10 premiers scores pour data1\n",
    "print(\"\\nScores sur 1000 pour les 10 premières lignes de data1:\")\n",
    "print(scores_data1[:10])\n",
    "\n",
    "# Utilisation de la méthode transform pour obtenir les scores sur 1000 pour data2\n",
    "# Assurez-vous que les noms de colonnes dans 'data2' correspondent à ceux utilisés dans le modèle\n",
    "scores_data2 = pd_scorer.transform(data2, 'Target')\n",
    "# Affichage des 10 premiers scores pour data2\n",
    "print(\"\\nScores sur 1000 pour les 10 premières lignes de data2:\")\n",
    "print(scores_data2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data1 = pd.DataFrame({\n",
    "    'Category1': np.random.choice(['A', 'B', 'C'], size=100),\n",
    "    'Category2': np.random.choice(['X', 'Y', 'Z'], size=100),\n",
    "    'Variable1': np.random.rand(100),\n",
    "    'Variable2': np.random.rand(100),\n",
    "    'Target': np.random.choice([0, 1], size=100),\n",
    "})\n",
    "formula = 'Target ~ Category1 + Category2 + Variable1 + Variable2'\n",
    "\n",
    "# Estimation du modèle de régression logistique avec statsmodels\n",
    "logit_model = sm.Logit.from_formula(formula, data1)\n",
    "fitted_model = logit_model.fit(disp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                 Target   No. Observations:                  100\n",
      "Model:                          Logit   Df Residuals:                       93\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Sat, 24 Feb 2024   Pseudo R-squ.:                 0.04872\n",
      "Time:                        09:44:43   Log-Likelihood:                -65.633\n",
      "converged:                       True   LL-Null:                       -68.994\n",
      "Covariance Type:            nonrobust   LLR p-value:                    0.3472\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Intercept          0.9446      0.670      1.410      0.159      -0.369       2.258\n",
      "Category1[T.B]    -0.2421      0.505     -0.479      0.632      -1.232       0.748\n",
      "Category1[T.C]     0.4621      0.528      0.875      0.381      -0.573       1.497\n",
      "Category2[T.Y]    -0.1554      0.564     -0.276      0.783      -1.261       0.950\n",
      "Category2[T.Z]    -0.6957      0.496     -1.402      0.161      -1.668       0.277\n",
      "Variable1         -0.9944      0.793     -1.253      0.210      -2.549       0.561\n",
      "Variable2          0.1065      0.710      0.150      0.881      -1.285       1.498\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(fitted_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "      <th>Variable1</th>\n",
       "      <th>Variable2</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.403836</td>\n",
       "      <td>0.768554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.064892</td>\n",
       "      <td>0.043604</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.253915</td>\n",
       "      <td>0.994551</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>X</td>\n",
       "      <td>0.246876</td>\n",
       "      <td>0.469945</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.696304</td>\n",
       "      <td>0.279560</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.668924</td>\n",
       "      <td>0.341880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.864168</td>\n",
       "      <td>0.091799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>C</td>\n",
       "      <td>Z</td>\n",
       "      <td>0.230185</td>\n",
       "      <td>0.094157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.499193</td>\n",
       "      <td>0.311413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>A</td>\n",
       "      <td>X</td>\n",
       "      <td>0.572004</td>\n",
       "      <td>0.979511</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category1 Category2  Variable1  Variable2  Target\n",
       "0          C         Z   0.403836   0.768554       0\n",
       "1          A         Z   0.064892   0.043604       1\n",
       "2          C         Z   0.253915   0.994551       1\n",
       "3          C         X   0.246876   0.469945       1\n",
       "4          A         Z   0.696304   0.279560       1\n",
       "..       ...       ...        ...        ...     ...\n",
       "95         A         Y   0.668924   0.341880       0\n",
       "96         A         Z   0.864168   0.091799       0\n",
       "97         C         Z   0.230185   0.094157       0\n",
       "98         A         Y   0.499193   0.311413       1\n",
       "99         A         X   0.572004   0.979511       1\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "predict requires that you use a DataFrame when predicting from a model\nthat was created using the formula api.\n\nThe original error message returned by patsy is:\nError evaluating factor: NameError: name 'Variable2' is not defined\n    Target ~  Variable1 + Variable2\n                          ^^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\patsy\\compat.py:36\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\patsy\\eval.py:169\u001b[0m, in \u001b[0;36mEvalEnvironment.eval\u001b[1;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[0;32m    168\u001b[0m code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcompile\u001b[39m(expr, source_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflags, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28meval\u001b[39m(code, {}, VarLookupDict([inner_namespace]\n\u001b[0;32m    170\u001b[0m                                     \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_namespaces))\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Variable2' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\statsmodels\\base\\model.py:1104\u001b[0m, in \u001b[0;36mResults._transform_predict_exog\u001b[1;34m(self, exog, transform)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1104\u001b[0m     exog \u001b[38;5;241m=\u001b[39m \u001b[43mdmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesign_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataframe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\patsy\\highlevel.py:290\u001b[0m, in \u001b[0;36mdmatrix\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    289\u001b[0m eval_env \u001b[38;5;241m=\u001b[39m EvalEnvironment\u001b[38;5;241m.\u001b[39mcapture(eval_env, reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 290\u001b[0m (lhs, rhs) \u001b[38;5;241m=\u001b[39m \u001b[43m_do_highlevel_design\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula_like\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lhs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\patsy\\highlevel.py:167\u001b[0m, in \u001b[0;36m_do_highlevel_design\u001b[1;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m design_infos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_design_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdesign_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNA_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# No builders, but maybe we can still get matrices\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\patsy\\build.py:888\u001b[0m, in \u001b[0;36mbuild_design_matrices\u001b[1;34m(design_infos, data, NA_action, return_type, dtype)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m factor_info \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m factor_info_to_values:\n\u001b[1;32m--> 888\u001b[0m     value, is_NA \u001b[38;5;241m=\u001b[39m \u001b[43m_eval_factor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNA_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    889\u001b[0m     factor_info_to_isNAs[factor_info] \u001b[38;5;241m=\u001b[39m is_NA\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\patsy\\build.py:63\u001b[0m, in \u001b[0;36m_eval_factor\u001b[1;34m(factor_info, data, NA_action)\u001b[0m\n\u001b[0;32m     62\u001b[0m factor \u001b[38;5;241m=\u001b[39m factor_info\u001b[38;5;241m.\u001b[39mfactor\n\u001b[1;32m---> 63\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactor_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Returns either a 2d ndarray, or a DataFrame, plus is_NA mask\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\patsy\\eval.py:568\u001b[0m, in \u001b[0;36mEvalFactor.eval\u001b[1;34m(self, memorize_state, data)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, memorize_state, data):\n\u001b[1;32m--> 568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemorize_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_code\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmemorize_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\patsy\\eval.py:551\u001b[0m, in \u001b[0;36mEvalFactor._eval\u001b[1;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[0;32m    550\u001b[0m inner_namespace \u001b[38;5;241m=\u001b[39m VarLookupDict([data, memorize_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransforms\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m--> 551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_and_wrap_exc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mError evaluating factor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    552\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    553\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mmemorize_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_env\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m                         \u001b[49m\u001b[43minner_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_namespace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\patsy\\compat.py:43\u001b[0m, in \u001b[0;36mcall_and_wrap_exc\u001b[1;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     exec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise new_exc from e\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m# In python 2, we just let the original exception escape -- better\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m# than destroying the traceback. But if it's a PatsyError, we can\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# at least set the origin properly.\u001b[39;00m\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'Variable2' is not defined\n    Target ~  Variable1 + Variable2\n                          ^^^^^^^^^",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 83\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_scores\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Utilisation de la classe PdScorer\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m scorer \u001b[38;5;241m=\u001b[39m \u001b[43mPdScorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfitted_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTARGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m grid_scores_df \u001b[38;5;241m=\u001b[39m scorer\u001b[38;5;241m.\u001b[39mget_grid_scores()\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Affichage de la grille de score\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[29], line 26\u001b[0m, in \u001b[0;36mPdScorer.__init__\u001b[1;34m(self, fitted_model, data, target_col)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_col \u001b[38;5;241m=\u001b[39m target_col\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_grid_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[29], line 53\u001b[0m, in \u001b[0;36mPdScorer.create_grid_scores\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[variable] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m sm\u001b[38;5;241m.\u001b[39madd_constant(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[variable])\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Prédiction des probabilités\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Création de classes basées sur les quantiles\u001b[39;00m\n\u001b[0;32m     56\u001b[0m classes \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mqcut(y_prob, q\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, \u001b[38;5;241m0.8\u001b[39m, \u001b[38;5;241m1.0\u001b[39m], labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\statsmodels\\base\\model.py:1173\u001b[0m, in \u001b[0;36mResults.predict\u001b[1;34m(self, exog, transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03m    Call self.model.predict with self.params as the first argument.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[38;5;124;03m    returned prediction.\u001b[39;00m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1173\u001b[0m     exog, exog_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_predict_exog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1176\u001b[0m     predict_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams, exog, \u001b[38;5;241m*\u001b[39margs,\n\u001b[0;32m   1177\u001b[0m                                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exog_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(predict_results,\n\u001b[0;32m   1180\u001b[0m                                               \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_values\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\statsmodels\\base\\model.py:1111\u001b[0m, in \u001b[0;36mResults._transform_predict_exog\u001b[1;34m(self, exog, transform)\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m   1106\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict requires that you use a DataFrame when \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1107\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicting from a model\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mthat was created using the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1108\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformula api.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1109\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThe original error message returned by patsy is:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1110\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mstr\u001b[39m(exc))))\n\u001b[1;32m-> 1111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(msg)\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orig_exog_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(exog) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict:\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exog_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mPatsyError\u001b[0m: predict requires that you use a DataFrame when predicting from a model\nthat was created using the formula api.\n\nThe original error message returned by patsy is:\nError evaluating factor: NameError: name 'Variable2' is not defined\n    Target ~  Variable1 + Variable2\n                          ^^^^^^^^^"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(42)\n",
    "data1 = pd.DataFrame({\n",
    "    #'Category1': np.random.choice(['A', 'B', 'C'], size=100),\n",
    "    #'Category2': np.random.choice(['X', 'Y', 'Z'], size=100),\n",
    "    'Variable1': np.random.rand(100),\n",
    "    'Variable2': np.random.rand(100),\n",
    "    'Target': np.random.choice([0, 1], size=100),\n",
    "})\n",
    "formula = 'Target ~  Variable1 + Variable2'\n",
    "\n",
    "# Estimation du modèle de régression logistique avec statsmodels\n",
    "logit_model = sm.Logit.from_formula(formula, data1)\n",
    "fitted_model = logit_model.fit(disp=False)\n",
    "\n",
    "\n",
    "# Classe pour la grille de score\n",
    "class PdScorer:\n",
    "    def __init__(self, fitted_model, data, target_col):\n",
    "        self.model = fitted_model\n",
    "        self.data = data\n",
    "        self.target_col = target_col\n",
    "        self.grid_scores = self.create_grid_scores()\n",
    "\n",
    "    def create_grid_scores(self):\n",
    "        # Extraction des coefficients estimés du modèle\n",
    "        coefficients = self.model.params\n",
    "\n",
    "        # Vérifier si 'Intercept' est présent dans les coefficients\n",
    "        if 'Intercept' in coefficients.index:\n",
    "            # Exclure 'Intercept' de la grille de score\n",
    "            coefficients = coefficients.drop('Intercept')\n",
    "\n",
    "        # Normalisation des coefficients pour les rendre comparables\n",
    "        normalized_coefficients = (coefficients - coefficients.min()) / (coefficients.max() - coefficients.min())\n",
    "\n",
    "        # Création d'une grille de score sur mille basée sur les coefficients normalisés\n",
    "        grid_scores = np.round(normalized_coefficients * 1000).astype(int)\n",
    "\n",
    "        # Création d'un DataFrame pour stocker les informations de chaque classe\n",
    "        result_df = pd.DataFrame(columns=['Variable', 'Classe', 'P-Value', 'Note', 'Contribution', 'Taux_de_Defaut', 'Effectif'])\n",
    "\n",
    "        # Boucle sur les variables explicatives\n",
    "        for variable in normalized_coefficients.index:\n",
    "            # Extraction des variables explicatives\n",
    "            X = self.data[variable] if 'const' in self.data.columns else sm.add_constant(self.data[variable])\n",
    "\n",
    "\n",
    "            # Prédiction des probabilités\n",
    "            y_prob = self.model.predict(X)\n",
    "\n",
    "            # Création de classes basées sur les quantiles\n",
    "            classes = pd.qcut(y_prob, q=[0, 0.2, 0.4, 0.6, 0.8, 1.0], labels=False)\n",
    "\n",
    "            # Calcul des statistiques pour chaque classe\n",
    "            for classe in range(classes.nunique()):\n",
    "                indices = (classes == classe)\n",
    "                p_value = sm.stats.proportions_ztest(self.data.loc[indices, self.target_col].sum(), indices.sum())[1]\n",
    "                contribution = coefficients[variable] * (self.data.loc[indices, variable].mean() - self.data[variable].mean())\n",
    "                taux_defaut = self.data.loc[indices, self.target_col].mean()\n",
    "                effectif = indices.sum()\n",
    "\n",
    "                # Ajout des informations à result_df\n",
    "                result_df = result_df.append({\n",
    "                    'Variable': variable,\n",
    "                    'Classe': classe,\n",
    "                    'P-Value': p_value,\n",
    "                    'Note': grid_scores[variable],\n",
    "                    'Contribution': contribution,\n",
    "                    'Taux_de_Defaut': taux_defaut,\n",
    "                    'Effectif': effectif\n",
    "                }, ignore_index=True)\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def get_grid_scores(self):\n",
    "        return self.grid_scores\n",
    "\n",
    "# Utilisation de la classe PdScorer\n",
    "scorer = PdScorer(fitted_model, data1, 'TARGET')\n",
    "grid_scores_df = scorer.get_grid_scores()\n",
    "\n",
    "# Affichage de la grille de score\n",
    "print(grid_scores_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Category1[T.B]'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Category1[T.B]'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Utilisation de la classe PdScorer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m scorer \u001b[38;5;241m=\u001b[39m \u001b[43mPdScorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfitted_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTARGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m grid_scores_df \u001b[38;5;241m=\u001b[39m scorer\u001b[38;5;241m.\u001b[39mget_grid_scores()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Affichage de la grille de score\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 12\u001b[0m, in \u001b[0;36mPdScorer.__init__\u001b[1;34m(self, fitted_model, data, target_col)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_col \u001b[38;5;241m=\u001b[39m target_col\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_grid_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[26], line 35\u001b[0m, in \u001b[0;36mPdScorer.create_grid_scores\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Boucle sur les variables explicatives\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m normalized_coefficients\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Extraction des variables explicatives\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[variable] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconst\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;28;01melse\u001b[39;00m sm\u001b[38;5;241m.\u001b[39madd_constant(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Prédiction des probabilités\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     y_prob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\pandas\\core\\frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3896\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3898\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\cecil\\Documents\\Master 2\\Projet Nexialog\\.venv_pd\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Category1[T.B]'"
     ]
    }
   ],
   "source": [
    "# Utilisation de la classe PdScorer\n",
    "scorer = PdScorer(fitted_model, data1, 'TARGET')\n",
    "grid_scores_df = scorer.get_grid_scores()\n",
    "\n",
    "# Affichage de la grille de score\n",
    "print(grid_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Logit' object has no attribute 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_scores\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Utilisation de la classe PdScorer\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m scorer \u001b[38;5;241m=\u001b[39m \u001b[43mPdScorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m grid_scores_df \u001b[38;5;241m=\u001b[39m scorer\u001b[38;5;241m.\u001b[39mget_grid_scores()\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# Affichage de la grille de score\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[34], line 23\u001b[0m, in \u001b[0;36mPdScorer.__init__\u001b[1;34m(self, fitted_model, data, target_col)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_col \u001b[38;5;241m=\u001b[39m target_col\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_grid_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[34], line 27\u001b[0m, in \u001b[0;36mPdScorer.create_grid_scores\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_grid_scores\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m# Extraction des coefficients estimés du modèle\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m     coefficients \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Vérifier si 'Intercept' est présent dans les coefficients\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIntercept\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m coefficients\u001b[38;5;241m.\u001b[39mindex:\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;66;03m# Exclure 'Intercept' de la grille de score\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Logit' object has no attribute 'params'"
     ]
    }
   ],
   "source": [
    "# AVec var catégorielle \n",
    "\n",
    "np.random.seed(42)\n",
    "data1 = pd.DataFrame({\n",
    "    'Category1': np.random.choice(['A', 'B', 'C'], size=100),\n",
    "    'Category2': np.random.choice(['X', 'Y', 'Z'], size=100),\n",
    "    'Variable1': np.random.rand(100),\n",
    "    'Variable2': np.random.rand(100),\n",
    "    'Target': np.random.choice([0, 1], size=100),\n",
    "})\n",
    "formula = 'Target ~ Category1 + Category2 + Variable1 + Variable2'\n",
    "\n",
    "# Estimation du modèle de régression logistique avec statsmodels\n",
    "logit_model = sm.Logit.from_formula(formula, data1)\n",
    "fitted_model = logit_model.fit(disp=False)\n",
    "\n",
    "\n",
    "class PdScorer:\n",
    "    def __init__(self, fitted_model, data, target_col):\n",
    "        self.model = fitted_model\n",
    "        self.data = data\n",
    "        self.target_col = target_col\n",
    "        self.grid_scores = self.create_grid_scores()\n",
    "\n",
    "    def create_grid_scores(self):\n",
    "        # Extraction des coefficients estimés du modèle\n",
    "        coefficients = self.model.params\n",
    "\n",
    "        # Vérifier si 'Intercept' est présent dans les coefficients\n",
    "        if 'Intercept' in coefficients.index:\n",
    "            # Exclure 'Intercept' de la grille de score\n",
    "            coefficients = coefficients.drop('Intercept')\n",
    "\n",
    "        # Normalisation des coefficients pour les rendre comparables\n",
    "        normalized_coefficients = (coefficients - coefficients.min()) / (coefficients.max() - coefficients.min())\n",
    "\n",
    "        # Création d'une grille de score sur mille basée sur les coefficients normalisés\n",
    "        grid_scores = np.round(normalized_coefficients * 1000).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "        # Création d'un DataFrame pour stocker les informations de chaque classe\n",
    "        result_df = pd.DataFrame(columns=['Variable', 'Classe', 'P-Value', 'Note', 'Contribution', 'Taux_de_Defaut', 'Effectif'])\n",
    "\n",
    "        # Boucle sur les variables explicatives\n",
    "        for variable in normalized_coefficients.index:\n",
    "    # Extraire le nom de la variable sans le préfixe de catégorie\n",
    "            var_name = variable.split('[')[0].strip()\n",
    "\n",
    "    # Extraction des variables explicatives\n",
    "            if var_name in self.data.columns:\n",
    "                X = self.data[var_name] if 'const' in self.data.columns else sm.add_constant(self.data[var_name])\n",
    "\n",
    "\n",
    "            # Prédiction des probabilités\n",
    "            y_prob = self.model.predict(X)\n",
    "\n",
    "            # Création de classes basées sur les quantiles\n",
    "            classes = pd.qcut(y_prob, q=[0, 0.2, 0.4, 0.6, 0.8, 1.0], labels=False)\n",
    "\n",
    "            # Calcul des statistiques pour chaque classe\n",
    "            for classe in range(classes.nunique()):\n",
    "                indices = (classes == classe)\n",
    "                p_value = sm.stats.proportions_ztest(self.data.loc[indices, self.target_col].sum(), indices.sum())[1]\n",
    "                contribution = coefficients[variable] * (self.data.loc[indices, var_name].mean() - self.data[var_name].mean())\n",
    "                taux_defaut = self.data.loc[indices, self.target_col].mean()\n",
    "                effectif = indices.sum()\n",
    "\n",
    "                # Ajout des informations à result_df\n",
    "                result_df = result_df.append({\n",
    "                    'Variable': var_name,\n",
    "                    'Classe': classe,\n",
    "                    'P-Value': p_value,\n",
    "                    'Note': grid_scores[variable],\n",
    "                    'Contribution': contribution,\n",
    "                    'Taux_de_Defaut': taux_defaut,\n",
    "                    'Effectif': effectif\n",
    "                }, ignore_index=True)\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def get_grid_scores(self):\n",
    "        return self.grid_scores\n",
    "\n",
    "# Utilisation de la classe PdScorer\n",
    "scorer = PdScorer(logit_model, data1, 'Target')\n",
    "grid_scores_df = scorer.get_grid_scores()\n",
    "\n",
    "# Affichage de la grille de score\n",
    "print(grid_scores_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_pd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
